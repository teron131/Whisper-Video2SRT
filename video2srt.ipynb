{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folders Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_path():\n",
    "    if getattr(sys, 'frozen', False):\n",
    "        # Running in a bundle (executable created by PyInstaller)\n",
    "        return os.path.dirname(sys.executable)\n",
    "    elif '__file__' in globals():\n",
    "        # Running in a script or packaged environment\n",
    "        return os.path.dirname(os.path.abspath(__file__))\n",
    "    else:\n",
    "        # Running in a Jupyter notebook\n",
    "        return os.getcwd()\n",
    "\n",
    "base_path = get_base_path()\n",
    "\n",
    "video_dir = base_path + \"/video_input/\"\n",
    "audio_dir = base_path + \"/audio_output/\"\n",
    "srt_dir = base_path + \"/srt_output/\"\n",
    "source_lang = \"Cantonese\"\n",
    "\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "os.makedirs(srt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to Audio: FFmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_dir, audio_dir):\n",
    "    \"\"\"\n",
    "    Extracts audio from any file in the specified directory using ffmpeg. If the file \n",
    "    is not a video, ffmpeg will return an error. The extracted audio files are saved \n",
    "    in FLAC format in another directory.\n",
    "    \n",
    "    Args:\n",
    "    - video_dir (str): Directory containing the input files.\n",
    "    - audio_dir (str): Directory where the extracted audio files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Delete the directory and its contents if the directory exists\n",
    "    if os.path.exists(audio_dir):\n",
    "        shutil.rmtree(audio_dir)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(audio_dir):\n",
    "        os.makedirs(audio_dir)\n",
    "\n",
    "    video_files = [f for f in os.listdir(video_dir) if f != '.DS_Store']\n",
    "    for filename in tqdm(video_files, desc=\"Extracting audio\"):\n",
    "        print(filename)\n",
    "        video_file_path = os.path.join(video_dir, filename)\n",
    "        audio_file_name = os.path.splitext(filename)[0] + '.flac'\n",
    "        audio_file_path = os.path.join(audio_dir, audio_file_name)\n",
    "\n",
    "        # Convert video to audio using ffmpeg\n",
    "        os.system(f'ffmpeg -y -i \"{video_file_path}\" -q:a 0 -map a \"{audio_file_path}\" -hide_banner -loglevel error')\n",
    "\n",
    "        print(f\"Extracted audio from video: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now TV - 衛視電影台 - 《正義迴廊》.flac\n",
      "Extracted audio from video: Now TV - 衛視電影台 - 《正義迴廊》.flac\n",
      "陳奕迅FEAR AND DREAMS 香港演唱會｜第十五場 28 DEC ENCORE ｜《陀飛輪》.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio:  33%|███▎      | 2/6 [00:00<00:01,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio from video: 陳奕迅FEAR AND DREAMS 香港演唱會｜第十五場 28 DEC ENCORE ｜《陀飛輪》.flac\n",
      "周星驰搞笑片段 Part 1.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio:  50%|█████     | 3/6 [00:01<00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio from video: 周星驰搞笑片段 Part 1.flac\n",
      "張國榮 - 《最愛是誰 My Dearest》MV.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio:  67%|██████▋   | 4/6 [00:02<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio from video: 張國榮 - 《最愛是誰 My Dearest》MV.flac\n",
      "【周星馳】『粵語』我左青龍、右白虎，老牛在腰間，龍頭在胸口，人擋殺人，佛擋殺佛！《唐伯虎點秋香》 Flirting Scholar.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio:  83%|████████▎ | 5/6 [00:02<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio from video: 【周星馳】『粵語』我左青龍、右白虎，老牛在腰間，龍頭在胸口，人擋殺人，佛擋殺佛！《唐伯虎點秋香》 Flirting Scholar.flac\n",
      "007 周星馳 見家長.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio: 100%|██████████| 6/6 [00:02<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio from video: 007 周星馳 見家長.flac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_audio_from_video(video_dir=video_dir, audio_dir=audio_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription: Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_srt(seconds_float):\n",
    "    \"\"\"Converts a time in seconds to 'hh:mm:ss,ms' format for SRT.\"\"\"\n",
    "    hours, remainder = divmod(seconds_float, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    seconds, milliseconds = divmod(seconds, 1)\n",
    "    milliseconds = int(milliseconds * 1000)\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
    "\n",
    "def whisper_transcribe(input_directory, output_directory):\n",
    "    model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "    audio_files = [file for file in os.listdir(input_directory) if file.endswith('.flac')]  # Adjust the extension if needed\n",
    "\n",
    "    for audio_file in tqdm(audio_files, desc=\"Transcribing\"):\n",
    "        audio_path = os.path.join(input_directory, audio_file)\n",
    "        result = model.transcribe(audio_path, task=\"transcribe\", word_timestamps=True)\n",
    "\n",
    "        # Process and write SRT content\n",
    "        srt_content = []\n",
    "        counter = 1\n",
    "        for segment in result['segments']:\n",
    "            start_time_srt = convert_time_to_srt(segment['start'])\n",
    "            end_time_srt = convert_time_to_srt(segment['end'])\n",
    "            transcript = segment['text'].strip()  # Strip whitespace from the transcript\n",
    "            srt_content.append(f\"{counter}\\n{start_time_srt} --> {end_time_srt}\\n{transcript}\")\n",
    "            counter += 1\n",
    "\n",
    "        srt_output = \"\\n\\n\".join(srt_content)  # Join segments with two newlines\n",
    "        srt_filename = os.path.splitext(audio_file)[0] + '.srt'\n",
    "        srt_path = os.path.join(output_directory, srt_filename)\n",
    "\n",
    "        with open(srt_path, 'w', encoding='utf-8') as srt_file:\n",
    "            srt_file.write(srt_output)\n",
    "        \n",
    "        print(f\"Generated SRT: {srt_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/6 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m whisper_transcribe(input_directory\u001b[39m=\u001b[39;49maudio_dir, output_directory\u001b[39m=\u001b[39;49msrt_dir)\n",
      "\u001b[1;32m/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m audio_file \u001b[39min\u001b[39;00m tqdm(audio_files, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTranscribing\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     audio_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_directory, audio_file)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(audio_path, task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtranscribe\u001b[39;49m\u001b[39m\"\u001b[39;49m, word_timestamps\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Process and write SRT content\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t3ron/Library/CloudStorage/OneDrive-HKUSTConnect/Projects/Whisper-Video2SRT/video2srt.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     srt_content \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/transcribe.py:240\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    237\u001b[0m mel_segment \u001b[39m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(dtype)\n\u001b[1;32m    239\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 240\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[1;32m    241\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/transcribe.py:170\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    167\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m options \u001b[39m=\u001b[39m DecodingOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, temperature\u001b[39m=\u001b[39mt)\n\u001b[0;32m--> 170\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(segment, options)\n\u001b[1;32m    172\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    174\u001b[0m     compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    176\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39;49mrun(mel)\n\u001b[1;32m    826\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/decoding.py:718\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    715\u001b[0m tokenizer: Tokenizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\n\u001b[1;32m    716\u001b[0m n_audio: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 718\u001b[0m audio_features: Tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_audio_features(mel)  \u001b[39m# encoder forward pass\u001b[39;00m\n\u001b[1;32m    719\u001b[0m tokens: Tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_tokens])\u001b[39m.\u001b[39mrepeat(n_audio, \u001b[39m1\u001b[39m)\n\u001b[1;32m    721\u001b[0m \u001b[39m# detect language if requested, overwriting the language token\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/decoding.py:655\u001b[0m, in \u001b[0;36mDecodingTask._get_audio_features\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    653\u001b[0m     audio_features \u001b[39m=\u001b[39m mel\n\u001b[1;32m    654\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     audio_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencoder(mel)\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m audio_features\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m (\n\u001b[1;32m    658\u001b[0m     torch\u001b[39m.\u001b[39mfloat16 \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mfp16 \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mfloat32\n\u001b[1;32m    659\u001b[0m ):\n\u001b[1;32m    660\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    661\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maudio_features has an incorrect dtype: \u001b[39m\u001b[39m{\u001b[39;00maudio_features\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    662\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/model.py:170\u001b[0m, in \u001b[0;36mAudioEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m x \u001b[39m=\u001b[39m (x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_embedding)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m--> 170\u001b[0m     x \u001b[39m=\u001b[39m block(x)\n\u001b[1;32m    172\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_post(x)\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/model.py:136\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     kv_cache: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m ):\n\u001b[0;32m--> 136\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn_ln(x), mask\u001b[39m=\u001b[39;49mmask, kv_cache\u001b[39m=\u001b[39;49mkv_cache)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn:\n\u001b[1;32m    138\u001b[0m         x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[39m=\u001b[39mkv_cache)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/model.py:90\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     87\u001b[0m     k \u001b[39m=\u001b[39m kv_cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey]\n\u001b[1;32m     88\u001b[0m     v \u001b[39m=\u001b[39m kv_cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue]\n\u001b[0;32m---> 90\u001b[0m wv, qk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqkv_attention(q, k, v, mask)\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(wv), qk\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/model.py:105\u001b[0m, in \u001b[0;36mMultiHeadAttention.qkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     qk \u001b[39m=\u001b[39m qk \u001b[39m+\u001b[39m mask[:n_ctx, :n_ctx]\n\u001b[0;32m--> 105\u001b[0m qk \u001b[39m=\u001b[39m qk\u001b[39m.\u001b[39;49mfloat()\n\u001b[1;32m    107\u001b[0m w \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(qk, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(q\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m (w \u001b[39m@\u001b[39m v)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mflatten(start_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), qk\u001b[39m.\u001b[39mdetach()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "whisper_transcribe(input_directory=audio_dir, output_directory=srt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Extra Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the directory and its contents if the directory exists\n",
    "if os.path.exists(audio_dir):\n",
    "    shutil.rmtree(audio_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
